#!/usr/bin/env python3

import os
import argparse
import sys
import threading
from threading import Thread
import time
from tqdm import trange
import tqdm
from tempfile import mkstemp
import subprocess
from os.path import expanduser
import yaml
from Bio import Entrez
from multiprocessing import Process
import argcomplete

# Rotifer
rotifer_root = os.path.dirname(os.path.dirname(os.path.realpath(sys.argv[0])))
sys.path.insert(0,os.path.join(rotifer_root,"lib"))
from rotifer.db.ncbi import NcbiConfig
import rotifer.core.cli as corecli
import rotifer.core.functions as rcf

# Globals
__version__ = '0.5'
__authors__ = 'Gilberto Kaihami; Aureliano Guedes'
__rdoc__='''
DESCRIPTION:
Parallel esl-sfetch, with epost and efetch
'''

################
### Function ###
################

### Arguments
# TODO change for a better helper
def parse_cli():
    pfetchConfig = rcf.loadConfig(':apps.pfetch')
    parser = corecli.parser(description ='Parallel esl-sfetch, with epost and efetch')
    parser.add(rconfig=':cli.acc')

    parser.add(
        long_arg = '--database',
        short_arg = '-db',
        default = pfetchConfig['database'] or 'nr',
        dest = 'database',
        helper = 'Protein fasta DB'
   )

    parser.add(
        long_arg ='--api_key',
        helper = 'Insert a valid NCBI API key or a valid config file username',
        default = NcbiConfig["api_key"],
    )

    parser.add(
        short_arg = "-p",
        long_arg = '--progress',
        action = 'store_true',
        helper = "Progress bar",
    )

    parser.add(
        short_arg = '-t',
        long_arg = '--threads',
        default = pfetchConfig['threads'] if 'threads' in pfetchConfig else 5,
        arg_type = int,
        helper = 'Number pf threads (Default:5)',
    )

    argcomplete.autocomplete(parser)

    args = parser.parse_args()

    return (args)

################
### Checkers ###
################

def check_tmp():
    # create a temporary file
    check = True
    tmp = 'tmp.txt'
    x = 0
    while check:
        if tmp in os.listdir(os.getcwd()):
             x += 1
             tmp = 'tmp'+str(x)+'.txt'
        else:
             check = False
    return tmp

def find_entrez(accs, api_key):
    len_size = 500
    sub_accs = [accs[x:x+len_size] for x in range(0,len(accs), len_size)]
    for acc in sub_accs:

        tries = 0
        while tries < 2:
            try:
                to_save = Entrez.efetch(db = 'protein',
                                        rettype = 'fasta',
                                        retmode = 'text',
                                        id = ','.join(acc),
                                        api_key = api_key)
                out = [x for x in to_save.read().splitlines() if x != '']
                print('\n'.join(out))
                sys.stdout.flush()
                time.sleep(1)
                break
            except:
                tries +=1
                time.sleep(1)

def find_sequences(tmp_f, database, output, thread = 5, api_key = NcbiConfig['api_key']):
    os.system("cat %s | parallel -j 18 esl-sfetch %s 2> %s.err {} |tee %s " % (tmp_f, database, output, output))
    to_open = open('{0}.err'.format(output)).read().splitlines()
    missing_accs = [x.split(' ')[1] for x in to_open if x != '']

    n = len(missing_accs) // thread if len(missing_accs) // thread > 0 else 1
    sub_missing_accs = [missing_accs[x:x+n] for x in range(0, len(missing_accs), n)]
    jobs = []

    for x in range(len(sub_missing_accs)):
        p = Process(target = find_entrez, args = (sub_missing_accs[x], api_key ))
        jobs.append(p)
        p.start()

    try:
        for p in jobs:
            p.join()
    except KeyboardInterrupt:
        for p in jobs:
            p.terminate()
        sys.exit(2)

def progress(initial, final):
    try:
        t = 0
        checker = True
        pbar = tqdm.tqdm(total=initial)
        time.sleep(1)
        old = 0
        while checker:
            test = len([x for x in open(final).read().split('\n') if ">" in x])
            if old == test:
                t+=1

            pbar.update(test-pbar.n)
            old = test
            if test == initial:
                checker = False
                break
            if t >=100:
                checker = False
                pbar.close()
                break
            time.sleep(0.1)

        pbar.close()
        return 0
    except:
        pass

############
### MAIN ###
############

if __name__ == '__main__':
    Entrez.email = NcbiConfig['email']
    # Arguments
    args = parse_cli()

    # Load NCBI API key
    api_key = args.api_key

    # Number of threads
    threads = args.threads if args.threads <= 5 else 5

    # Checking if it is valid
    acc = args.accession
    fd, path_accession = mkstemp()

    with open(path_accession, 'a') as f:
        f.write('\n'.join(acc))

    fd2, path_output = mkstemp()
    first = Thread(target = find_sequences, args = (path_accession, args.database, path_output, threads, api_key))
    time.sleep(0.4)

    if args.progress:
        second = Thread(target = progress, args = (len(acc), path_output))
        second.start()

    first.start()
    try:
        first.join()
        if args.progress:
            second.join()

    except KeyboardInterrupt:
        first.terminate()
        if args.progress:
            second.terminate()
        sys.exit(2)
