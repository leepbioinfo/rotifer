#!/usr/bin/env python3
from rotifer.alchemy.connect import clickhouse
from clickhouse_driver import Client
from sqlalchemy import create_engine, MetaData
from sqlalchemy.orm import sessionmaker
import rotifer.core.functions as rcf
import datetime
import subprocess
import pandas as pd
from multiprocessing import Process
import os
import sys
import io

from Bio import SeqIO
from Bio import Entrez
import time
import shutil
import numpy as np
import warnings
from os.path import expanduser
from datetime import datetime as dt
import argcomplete
from clickhouse_driver import Client
from sqlalchemy import create_engine, MetaData
from sqlalchemy.orm import sessionmaker
import random, string
from clickhouse_sqlalchemy import Table, make_session, get_declarative_base, types, engines
import pandas as pd
uri = 'clickhouse://default:@localhost/rotifer'

import rotifer.core.cli as corecli

__version__ = 0.01
__authors__ = 'Gilberto Kaihami'

def parse_cli():
    parser = corecli.parser(description = 'Feed clickhouse database from assembly_summary file')

    # Add another options here

    parser.add( 
                dest = 'files',
                nargs = '*',
                helper = 'List of assembly summary',
                action = 'append',
                default = []
                )

    args = parser.parse_args()

    return args


def makeDB(verbose = False):
    home = expanduser("~") #Get home folder platform independent
    db = os.path.join(home, '.cache/rotifer/acc2operon')
    try:
        os.makedirs(db)
        return db
    except:
        if verbose:
            sys.stderr.write('## Cache folder already exists at: {0}\n'.format(db))
        return db

def assembly_summary(fi):
    col = open(fi)
    col.readline()
    col = col.readline().replace('#', '').strip()
    col = (col.split('\t'))

    df = pd.read_csv(fi, sep = '\t', skiprows= [0,1], header = None)
    df.columns = col
    return df

def verbose_msg(message = ''):
    now = dt.now().strftime('[%D %H:%M:%S]')
    if isinstance(message, list):
        message = ' '.join(message)
    sys.stderr.write('## {0} {1}\n'.format(now, message))
    sys.stderr.flush()

def nuc2gbk(gbks,db, verbose = False, api_key = ''):
    '''
    Get genbank file from nucleotide accession using Entrez
    ----------
    PARAMETERS:
    gbks:    list of nucleotides
    db:      folder to save the genbank
    verbose: verbose level
    api_key: Entrez API Key
    '''
    for nucleotide in gbks:
        if verbose:
            verbose_msg('Downloading {0} using efetch'.format(nucleotide))
        try:
            to_save = Entrez.efetch(db = 'nuccore',
                                    rettype = 'gbwithparts',
                                    retmode = 'text',
                                    id = nucleotide,
                                    api_key = api_key)

            out_handle = open(db + '/' + nucleotide + '.gbff', "w")
            out_handle.write(to_save.read())
            out_handle.close()
            to_save.close()
        except:
            if verbose:
                if isinstance(nucleotide, str):
                    sys.stderr.write(nucleotide+'\n')

def asm2ftp(gbks, db, verbose = True):
    '''
    Get genbank file from a list of asssemblies using ftp
    ----------
    PARAMETERS:
    gbks:    list of assemblies
    db       folder to save the genbank
    verbose: verbose level
    '''
    for ele in gbks:
        if verbose:
            verbose_msg('Downloading {0} using ftp'.format(str(ele)))
        tries_download = 0
        while tries_download < 10:
            try:
                gca, f1, f2, f3 = ele[0:3], ele [4:7], ele[7:10], ele[10:13]
                sub2 = subprocess.Popen('''curl -l ftp://ftp.ncbi.nlm.nih.gov/genomes/all/{0}/{1}/{2}/{3}/* 2> /dev/null| \
            grep "{4}" 2> /dev/null'''.format(gca, f1, f2, f3, ele), shell = True, stdout = subprocess.PIPE)
                genome = sub2.communicate()[0].decode('utf-8').replace('\n', '')
                sub1 = subprocess.Popen('''curl -l ftp://ftp.ncbi.nlm.nih.gov/genomes/all/{0}/{1}/{2}/{3}/* 2> /dev/null |\
            grep "{4}" | parallel curl -l ftp://ftp.ncbi.nlm.nih.gov/genomes/all/{0}/{1}/{2}/{3}/{5}/ 2> /dev/null'''.format(gca, f1, f2,f3, ele, '{}'), shell = True, stdout = subprocess.PIPE)
                features = sub1.communicate()[0].decode('utf-8').splitlines()
                for feature in features:
                    file2save = db+'/'+ele
                    if file2save+'.gbff' not in os.listdir(db):
                        if '_genomic.gbff' in feature and '_cds' not in feature and '_rna_' not in feature:
                            download = 'curl ftp://ftp.ncbi.nlm.nih.gov/genomes/all/{0}/{1}/{2}/{3}/{4}/{5} --output {6}.gbff.gz 2> /dev/null'.format(gca, f1, f2, f3, genome, feature, file2save)
                            subprocess.Popen([download], shell = True).wait()
                            subprocess.Popen(['gunzip -f {0}.gbff.gz'.format(file2save)], shell = True).wait()
                break

            except:
                tries_download +=1
                time.sleep(0.3)

def features2df(gbk, df, db = '', pair_acc = '', verbose = False):
    '''
    Parameters:
    gbk:  assembly or nucleotide
    df:   empty dataframe
    db:   Database folder
    pair_acc
    '''
#    sys.stderr.write(gbk+'\n')
    # , accs = sub_accs, pair_acc = old_new_acc

    # Create engine

    uri = 'clickhouse://default:@localhost/rotifer'
    engine = create_engine(uri)
    session = make_session(engine)
    metadata = MetaData(bind=engine)
    metadata.reflect(bind = engine)
    date = datetime.date(int(datetime.datetime.today().strftime('%Y')), int(datetime.datetime.today().strftime('%m')), int(datetime.datetime.today().strftime('%d')))
    # Check if gbk is present in the database
    if not engine.execute(f"select DISTINCT nuc_asm FROM genomes where assembly = '{gbk}'").fetchone():
        if verbose:
            verbose_msg(f'## loading {gbk}')

        s = time.time()
        fts = SeqIO.index(os.path.join(db,'gbff')+'/'+gbk+'.gbff', "genbank")
        e = time.time()
        if verbose:
            verbose_msg(f'## total time to load: {e-s}')
        df = pd.DataFrame()
        not_types = []

        tot = 0
        for k,rec in fts.items():
            seq_type = 'chromosome'
            gbk_id = k
            topology = rec.annotations['topology']
            organism = rec.annotations['organism']
            taxonomy = '; '.join(rec.annotations['taxonomy'])
            try:
                assembly = [x.split(':')[-1] for x in rec.dbxrefs if 'Assembly' in x][0]
            except:
                assembly = '.'
            if not assembly:
                assembly = '.'

            if rec.features:
                res = []
                ft_order = {}

                for (idx, ft) in enumerate(rec.features):
                    if 'plasmid' in ft.qualifiers:
                        seq_type = 'plasmid'
                    if ft.type not in not_types:
                        feature_type = ft.type
                        sub_fts = ft.qualifiers
                        pid = sub_fts['protein_id'][0] if 'protein_id' in sub_fts.keys() else ''
                        if pid == '' and 'CDS' in ft.type:
                            feature_type = 'PSE'

                        # this part is new
                        if feature_type in ft_order.keys():
                            ft_order[feature_type] +=1
                        if feature_type not in ft_order.keys():
                            ft_order[feature_type] = 1
                        locus_tag = sub_fts['locus_tag'][0] if 'locus_tag' in sub_fts.keys() else '.'

                        location = ft.location
                        start = str(location.start+1).replace('>', '').replace('<', '')
                        end = str(location.end).replace('>', '').replace('<', '')

                        try:
                            strand = str(location.strand)

                        except:
                            strand = '.'

                        gene = sub_fts['gene'][0] if 'gene' in sub_fts.keys() else '.'
                        plen = len(ft.qualifiers['translation'][0]) if 'translation' in ft.qualifiers.keys() else ''
                        product = sub_fts['product'][0] if 'product' in sub_fts.keys() else ''
                        res.append({'internal_id':idx, 'nucleotide': gbk_id,
                                    'assembly': assembly,
                                    'topology': topology, 'start': str(start),
                                    'end':str(end), 'strand': strand,
                                    'pid': pid, 'type': feature_type,
                                    'plen': str(plen), 'locus': locus_tag,
                                    'seq_type': seq_type, 'gene':gene,
                                    'product': product, 'organism': organism,
                                    'taxonomy': taxonomy,
                                    'feature_order':ft_order[feature_type],
                                    'nuc_asm': gbk,
                                    'date': date

                                    })

                # write res here
                client = Client('localhost')

                # Insert
                s = time.time()

                if len(res) > 0:
                    if verbose:
                        verbose_msg(f'## Inserting into clickhouse DB {gbk}')

                    client.execute('Insert into rotifer.genomes values', res)

                    e = time.time()
                    # if verbose:
                    #     verbose_msg(f'## Total time to insert {e-s}')

def _multi_ft2df(ls_gbks = [], db = '', verbose = False):
    for gbk in set(ls_gbks):
        if verbose:
            verbose_msg('Ft2df of {0}'.format(gbk))

        try:
            df = pd.DataFrame()
            features2df(gbk, df, db = db, verbose = verbose)
        except:
            if verbose:
                _ = 'Error ft2df {0}'.format(gbk)
                verbose_msg(str(_))

if __name__ == '__main__':
    threads = 5
    verbose = True
    db = makeDB(verbose)
    api_key = ''
    gbks_folder = os.path.join(db, 'gbff')

    args = parse_cli()

    for arg in args.files[0]:
        asms = assembly_summary(arg)
        click = clickhouse(table_name = 'genomes')
        conn = click.conn
        ls_gbks_parsed = rcf._flatten([list(x) for x in conn.execute('''
                            SELECT DISTINCT nuc_asm from genomes
                            ''').fetchall()])

        asms2get = asms[~(asms['assembly_accession'].isin(ls_gbks_parsed))]

        find_gbks = asms2get['assembly_accession'].values
        print(len(find_gbks))
        jobs = []
        n = len(find_gbks)//threads if len(find_gbks)//threads > 0 else 1
        sub_gbks = [find_gbks[x:x+n] for x in range(0, len(find_gbks), n)]
        for x in range(len(sub_gbks)):
            p = Process(target = asm2ftp, args = (sub_gbks[x], gbks_folder))
            jobs.append(p)
            p.start()

        try:
            for p in jobs:
                p.join()

        except KeyboardInterrupt:
            for p in jobs:
                p.terminate()
            sys.exit(2)

        jobs = []

        ls_gbks = asms2get['assembly_accession'].values
        print(len(ls_gbks))
        n = len(ls_gbks)//int(1) if len(ls_gbks)//int(1) > 0 else 1
        sub_ls_gbks = [ls_gbks[x:x+n] for x in range(0,len(ls_gbks), n)]

        for x in range(len(sub_ls_gbks)):
            p = Process(target = _multi_ft2df, args = (sub_ls_gbks[x], db, verbose))
            jobs.append(p)
            p.start()
        try:
            for p in jobs:
                p.join()

        except KeyboardInterrupt:
            for p in jobs:
                p.terminate()
            sys.exit(2)

        try:
            if verbose:
                verbose_msg('Cleaning cache')
            gbks_folder = os.path.join(db, 'gbff')
            for gb in os.listdir(gbks_folder):
                os.remove(os.path.join(gbks_folder, gb))

        except:
            pass
        try:
            if args.fun:
                sys.stderr.write(args.fun.fun)
        except:
            pass

