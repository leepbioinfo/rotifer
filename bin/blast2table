#!/usr/bin/env perl

use FindBin;
use lib "$FindBin::RealBin/../perl/lib";
use Rotifer::Utils qw(describe_subclasses);
use File::Basename;
use warnings;
use strict;

# Loading parsers
my $parser = undef;
my @parsers = qw(Bio::SearchIO RG::Blast::Parser);
foreach (@parsers) {
   eval "require $_";
   if (!$@) {
      $parser = $_;
      last;
   }
}
if (defined $parser) {
   warn "Using parsing $parser";
   no strict "refs";
   $parser =~ tr/A-Z/a-z/;
   $parser =~ s/::/_/g;
   $parser = "process_$parser";
   $parser = \&{"$parser"};
   use strict "refs";
} else {
   die "No Blast parser library found! Compatible libraries are: ",join(", ",@parsers);
}

# Parse command line options
my $CONFIG = parse_configuration();

# Parse report and print table
my $ColNames = $CONFIG->column;
print join("\t",@$ColNames),"\n" if ($CONFIG->header);
foreach my $file (@ARGV) {
    my @parsed = $parser->($CONFIG, $file);
    foreach my $hsp (@parsed) {
	&swap($hsp) if ($CONFIG->swap);
	print join("\t",map { exists $hsp->{$_} && length $hsp->{$_} ? $hsp->{$_} : "" } @{$ColNames}),"\n";
    }
}

# Terminate execution nicely
exit 0;

#####
# Add your subroutines below
#####

sub fix_ncbi_name {
    my ($result,$data,$field) = @_;
    if ($data->{$field} =~ /^Query_\d+/) {
	my $desc = $result->query_description;
	if (defined $desc && length $desc) {
	    my ($rename) = ($desc =~ /^(\S+)/);
	    $desc =~ s/^\S+//;
	    $desc = $data->{$field} . $desc;
	    $data->{$field} = $rename;
	}
    }
    return $data;
}

sub each_input_stream {
    my $input = shift;
    use Scalar::Util qw(reftype);

    # Hardcoded!
    my $gunzip = "gzip -dc";
    my $bunzip = "bzip2 -dc";

    # Input is a GLOB (STDIN)
    if (my $reftype = reftype($input)) {
	if ($reftype eq "GLOB") {
	    return($input);
	} else {
	    die "Unknown reference type $reftype: $input is not a GLOB.";
	}
    }
    
    # Input is a file
    elsif ( -f $input ) {
      COMPRESSED: {
	  $_ = $input;
	  /\.gz/ && do {
              open(STREAM,"$gunzip $_ |") || die "Could not open file $_";
	      last COMPRESSED;
	  };
	  /\.bz2/ && do {
              open(STREAM,"$bunzip $_ |") || die "Could not open file $_";
	      last COMPRESSED;
	  };
          open(STREAM,"<$_") || die "Could not open file $_";
	};
	return(\*STREAM);
    }
    
    # Anything else?
    else {
	warn "File $input not found!";
    }

    return undef;
}

# The function below isn't working because RG::BLAST::Parser
# Doesn't support newer BLAST versions
sub process_rg_blast_parser {
    my ($conf, $file) = @_;
    die "RG::BLAST::Parser is unable to parse blastxml!" if ($conf->format eq 'blastxml');
    my $report = undef;
    my $stream = each_input_stream($file);
    eval { $report = RG::Blast::Parser->new($stream,$file) };
    die "Failed to parse blast result $file: exception caught" if( $@ && $@ =~ /^parser error/ );
    close($stream);
    return @parsed;
}

sub process_bio_searchio {
    my ($conf, $file) = @_;

    # Columns
    my $colNames = $conf->column;

    # Input options
    my $basename = undef;
    my $stream = each_input_stream($file,1);
    my %opts = ("-fh", $stream, %{ $conf->input_args });
    $opts{'-format'} = $conf->format if ($conf->format ne 'auto');
    $basename = fileparse($file, @{ $CONFIG->force_basename }) if (scalar @{ $CONFIG->force_basename });

    # Parse report using Bioperl
    require Bio::SearchIO;
    my $report = undef;
    if ($conf->warn_on_error) {
	eval { $report = Bio::SearchIO->new(%opts) };
	warn "Error while parsing BLAST report $file:\n$@" if (defined $@);
	return ();
    } else {
	$report = Bio::SearchIO->new(%opts);
    }

    # Process type
    if (defined $conf->type && $conf->format eq 'blastxml' && $report->can("blasttype")) {
	$report->blasttype($conf->type);
    }

    # Process each result in the parsed report
    my @parsed = (); my %index = ();
    my $iteration_number = 1; # BioPerl's blast.pm parser doesn't know about iterations! Only blastxml does!
    my $last_query = undef;
    while (my $result = $report->next_result) {
	# Mode-independent steps: loading query name
	# Follow $data to see the definition of every printed data
	my $data = { 'query_name' => $result->query_name, 'query_length' => $result->query_length };
	&fix_ncbi_name($result,$data,'query_name');
	if (defined $basename) {
	    $data->{'query_name'} = $basename;
	} elsif (defined $conf->rename_query) {
	    $data->{'query_name'} = ref($conf->rename_query) ? $conf->rename_query->($data->{'query_name'}, $file) : $conf->rename_query;
	} elsif (!defined $data->{'query_name'} || length($data->{'query_name'}) == 0) {
	    print STDERR "Missing query name in report $file! Using filename...\n";
	    $data->{'query_name'} = $file;
	}

	# Mode-independent: extracting coordinates from query name (i.e. whether the query is a fragment)
	($data->{'_query_region_start'},$data->{'_query_region_end'}) = 
	    ($data->{'query_name'} =~ /^[^\|]+\|[^\|]+\|(\d+)\|(\d+)$/); # My naming format
	($data->{'_query_region_start'},$data->{'_query_region_end'}) =
	    ($data->{'query_name'} =~ m|^[^/]+/(\d+)\-(\d+)$|); # Alignment program's style
	foreach my $method (@{ $conf->clean }) {
	    ($data->{'query_name'}, $data->{'query_orig'}) = $method->($data->{'query_name'},'query',$result);
	}

	# OrthoMCL-specific result processing
	if ($conf->mode eq 'orthomcl') {
	    ($data->{'query_taxon'} = $data->{'query_name'}) =~ s/\|.+$//;
	}

	if ($conf->format eq 'blast' && $conf->type eq 'psiblast') {
	    $iteration_number = 1 if (!defined $last_query || $last_query ne $data->{'query_name'});
	    next if ($conf->iteration > 0 && $iteration_number > $conf->iteration);
	}

	# Process desired iteration
	my @array = ($result);
	while (my $it = $result->can('next_iteration') ? $result->next_iteration : shift(@array)) {
	    $iteration_number = $it->number if ($it->can('number'));
	    last if ($conf->iteration > 0 && $iteration_number > $conf->iteration);
	    $data->{'iteration'} = $iteration_number;

	    # Mode-independent iteration processing
	    print STDERR "Processing iteration ($iteration_number) [$result $it]\n" if ($conf->debug);

	    # Process hits
	    while (my $hit = $it->next_hit) {
		next if ($hit->num_hsps eq '-' || !$hit->num_hsps); # Avoid hits without HSPs

		# Mode-independent: parse hit name
		$data->{'hit_name'} = $hit->name;
		foreach my $method (@{ $conf->clean }) {
		    ($data->{'hit_name'},$data->{'hit_orig'}) = $method->($data->{'hit_name'},'hit',$hit);
		}
		#$data->{'hit_name'} =~ s/^[^\|]+\|([^\|]+)\|\S+/$1/ if ($conf->clean);
		if ($data->{'hit_name'} =~ /^gnl\|BL_ORD_ID\|\d+$/) { # Exception: XML reports may be missing hit names in seq_id
		    (my $desc = $hit->description) =~ s/^(\S+)\s+.+$/$1/;
		    $data->{'hit_name'} = $desc if (defined $desc && length $desc);
		}
		$data->{'hit_length'} = $hit->length;

		# Processing hit for OrthoMCL: query_name hit_name query_taxon hit_taxon evalue_matisse evalue_exponent percent_identity percent_match
		if ($conf->mode eq 'orthomcl') {
		    ($data->{'hit_taxon'} = $data->{'hit_name'}) =~ s/\|.+$//;
		    (my $evalue = $hit->significance) =~ s/^e/1e/;
		    $evalue = sprintf("%.0e",$evalue);
		    next if (defined($conf->evalue) && $evalue > $conf->evalue);
		    ($data->{'evalue_matisse'}, $data->{'evalue_exponent'}) = split(/e/, $evalue);
		    $data->{'evalue_matisse'}  = sprintf("%.0f",$data->{'evalue_matisse'});
		    $data->{'evalue_exponent'} = sprintf("%d",$data->{'evalue_exponent'});
		    if ($data->{'query_length'} < $hit->length) {
			$data->{'percent_match'} = $hit->frac_aligned_query*100;
		    } else {
			$data->{'percent_match'} = $hit->frac_aligned_hit*100;
		    }
#		    print join("\t",map { $data->{$_} } @{$colNames}),"\n";
#		    next; # No need to further process HSPs in this case
		}

		# Parsing HSPs
		while (my $hsp = $hit->next_hsp) {
		    # Select HSP based on e-value
		    $data->{'evalue'} = $hsp->evalue; 
		    $data->{'evalue'} =~ s/\,$//;
		    $data->{'evalue'} = 1 . $data->{'evalue'} if ($data->{'evalue'} =~ /^e/);
		    $data->{'evalue'} = 
			$data->{'evalue'} > 1  ? sprintf("%.1f",$data->{'evalue'}) : 
			$data->{'evalue'} == 0 ? 0 : sprintf("%.3e",$data->{'evalue'});
		    next if (defined($conf->evalue) && $data->{'evalue'} > $conf->evalue);

		    # Loading more HSP data...
		    $data->{'bits'}             = defined $hsp->bits ? $hsp->bits > 99 ? sprintf("%.0f",$hsp->bits) : sprintf("%.1f",$hsp->bits) : 'NA';
		    $data->{'percent_identity'} = sprintf("%.2f",$hsp->percent_identity);
		    $data->{'num_identical'}    = $hsp->num_identical;
		    $data->{'length_aln_total'} = $hsp->length('total');
		    $data->{'gaps_total'}       = scalar($hsp->seq_inds('hit', 'gap', 1)) + scalar($hsp->seq_inds('query', 'gap', 1));
		    my @homology = ($hsp->homology_string =~ /( |\+)/g);
		    $data->{'mismatch_total'}   = scalar(@homology) - $hsp->gaps('total');

		    # Correct query coordinates, if needed
		    $data->{'query_start'} = $hsp->start('query');
		    $data->{'query_end'} = $hsp->end('query');
		    if (defined $data->{'_query_region_start'}) { # Coordinates?
			$data->{'query_start'} = $data->{'query_start'} + $data->{'_query_region_start'} - 1;
			$data->{'query_end'}   = $data->{'query_end'}   + $data->{'_query_region_start'} - 1;
		    }

		    # Hit coordinates
		    $data->{'hit_start'} = $hsp->start('hit');
		    $data->{'hit_end'}   = $hsp->end('hit');

		    # Calculate coverage
		    if ($data->{'query_length'}) {
			$data->{'query_coverage'} = sprintf("%.3f",($data->{'query_end'}-$data->{'query_start'}+1)/$data->{'query_length'});
		    } else {
			$data->{'query_coverage'} = 'NA';
		    }
		    if ($hit->length) {
			$data->{'hit_coverage'} = sprintf("%.3f",($data->{'hit_end'}-$data->{'hit_start'}+1)/$hit->length);
		    } else {
			$data->{'hit_coverage'} = 'NA';
		    }

		    # Check for redundant HSPs, i.e. HSPs that overlap both in the query and the hit
		    my $is_new = 1;
		    if ($conf->non_redundant_hsps) {
			if (exists $index{$data->{'query_name'}.":".$data->{'hit_name'}}) {
			    #print join(" ","Check",map { $data->{$_} } qw(query_name query_start query_end hit_name hit_start hit_end)),"\n";
			    foreach my $i (@{ $index{$data->{'query_name'}.":".$data->{'hit_name'}} }) {
				if (same_hsp($conf, $parsed[$i], $data)) {
				    #print join(" ","Same",map { $parsed[$i]->{$_} } qw(query_name query_start query_end hit_name hit_start hit_end)),"\n";
				    if ($parsed[$i]->{'evalue'} < $conf->threshold) {
					# If we have already found the first HSP lower than the inclusion threshold, we
					# will select and store the widest coordinates but keep the E-value and iteration
					foreach my $j (qw(hit query)) { # 2: hit, 6: query
					    my $old = $parsed[$i]->{"${j}_end"} - $parsed[$i]->{"${j}_start"};
					    my $new = $data->{"${j}_end"} - $data->{"${j}_start"};
					    if ($new > $old) {
						$parsed[$i]->{"${j}_end"}   = $data->{"${j}_end"};
						$parsed[$i]->{"${j}_start"} = $data->{"${j}_start"};
					    }
					}
				    } elsif ($data->{"evalue"} < $parsed[$i]->{"evalue"}) {
					# Replace a previously loaded HSP with one with lower E-value
					$parsed[$i] = { %$data }; # Copy
				    }
				    $is_new = 0; # If we made it to this line, then we already loaded this HSP
				    last;        # Abort inspecting loaded HSPs when the first equivalent HSP is found
				} # if (same_hsp($conf, $parsed[$i], $data))
			    } # foreach my $i (@{ $index{$data->{'query_name'}.":".$data->{'hit_name'}} })
			} # if (exists $index{$data->{'query_name'}.":".$data->{'hit_name'}}) {
		    } # if ($conf->non_redundant_hsps)

		    # Just print if redundancy is not an issue
		    elsif ($conf->mode ne 'orthomcl')  { #if ($conf->mode ne 'orthomcl') {
			my $copy = { %$data };
			&swap($copy) if ($conf->swap);
			print join("\t",map { $copy->{$_} } @{$colNames}),"\n";
			next;
		    }

		    # Add new HSP
		    if ($is_new) {
			my $copy = { %$data };
			#&swap($copy) if ($conf->swap);
			push(@parsed, $copy); # Copy each HSP's data to this array
			push(@{ $index{$data->{'query_name'}.":".$data->{'hit_name'}} }, $#parsed);
		    }
		} # while (my $hsp = $hit->next_hsp)

		if ($conf->mode eq 'orthomcl' && scalar @parsed) {
		    $data = shift(@parsed);
		    foreach my $parsed (@parsed) {
			$data->{'num_identical'} += $parsed->{'num_identical'};
			$data->{'length_aln_total'} += $parsed->{'length_aln_total'};
		    }
		    $data->{'percent_identity'} = sprintf("%.1f", ($data->{'num_identical'}*100)/$data->{'length_aln_total'});
		    $data->{'percent_identity'} =~ s/\.0$//;
		    #my $length = $data->{'query_length'} < $hit->length ? $data->{'query_length'} : $hit->length;
		    #$data->{'percent_match'} = sprintf("%.1f",($data->{'length_aln_total'}*100/$length));
		    &swap($data) if ($conf->swap);
		    print join("\t",map { $data->{$_} } @{$colNames}),"\n";
		    @parsed = (); %index = ();
		}
	    } # while (my $hit = $it->next_hit)
	} # foreach my $iteration (@iteration)

	# Count iterations/rounds for broken Bio::SearchIO::blast parser
	if ($conf->format eq 'blast') {
	    if ($conf->type =~ /psiblast/i) {
		$iteration_number++;
		last if ($conf->single_query && $conf->iteration > 0 && $iteration_number > $conf->iteration);
	    } else {
		$iteration_number = 1;
	    }
	    $last_query = $data->{'query_name'};
	}
    } # while (my $result = $report->next_result)

    close($stream);
    return @parsed;
}

####
# Check for overlaps in BOTH the query and hit sequences
# This subroutine supports tolerance of overlaps based on percentage
# (float, e.g. 1.0) or number of residues (integer, e.g. 1).
sub same_hsp {
    my ($config, $hash1, $hash2) = @_;

    my $overlaps = 0; # 0 Means $hash1 and $hash2 are not the same
    foreach my $i (qw(hit query)) { # 2: hit, 6: query
	my $max_start = $hash1->{"${i}_start"} > $hash2->{"${i}_start"} ? $hash1->{"${i}_start"} : $hash2->{"${i}_start"};
	my $min_end   = $hash1->{"${i}_end"}   < $hash2->{"${i}_end"}   ? $hash1->{"${i}_end"}   : $hash2->{"${i}_end"};
	my $overlap_length = $min_end - $max_start + 1;
	if ($config->overlap =~ /\d*\.\d+/ || $config->overlap =~ /\d+e-\d+/) { # Compare both HSPs when using percentage!
	    my $max_overlap1 = $config->overlap * ($hash1->{"${i}_end"} - $hash1->{"${i}_start"} + 1);
	    my $max_overlap2 = $config->overlap * ($hash2->{"${i}_end"} - $hash2->{"${i}_start"} + 1);
	    $overlaps++ if ($overlap_length > $max_overlap1 && $overlap_length > $max_overlap2);
	} else { # Cutoff set in number of residues: compare length of overlapping region to cutoff
	    $overlaps++ if ($overlap_length > $config->overlap);
	}
    }

    return $overlaps == 2 ? 1 : 0; # 0 => != HSPs, 1 => hit overlap, 2 => query and hit overlap
}

sub CDD {
    my ($name, $type, $obj) = @_;
    if ($type eq 'query') {
	return genbank2gi($name);
    } else {
	my @desc = split(/\, /,$obj->description);
	$desc[1] = $name unless (defined $desc[1]);
	return ($desc[1],$desc[0]);
    }
}

sub genbank2gi {
    my $name = shift;
    return ($name,$name) unless ($name =~ /^gi\|[^\|]+\|\w+\|+[^\|]+/);
    my @name = split(/\|+/,$name);
    return ($name[1],$name);
}

sub genbank2acc {
    my $name = shift;
    return $name unless ($name =~ /^gi\|[^\|]+\|\w+\|+[^\|]+/);
    my @name = split(/\|+/,$name);
    $name[3] =~ s/\.\d+$//;
    return ($name[3],$name);
}

sub profiledb {
    my $name = $_[0];
    $name =~ s/(\_\S+)?\.\d+$// if ($_[1] eq "hit");
    return ($name,$_[0]);
}

sub swap {
    my $data = shift;
    foreach my $column (qw(name start end coverage length)) { 
	($data->{"query_$column"}, $data->{"hit_$column"}) = ($data->{"hit_$column"}, $data->{"query_$column"});
    }
}

######
# Command line parsing, debugging and help messages
######

sub parse_configuration {
    # Parser definition
    use Application::Config qw(:argcount GetConfig);
    my $appconfig = GetConfig(# The argument to this method is a hash of hashes
			      # Input format
			      'format' => {
				  ACTION   => sub { my ($s,$n,$v) = @_; if ($v =~ /^help$/i) { print describe_subclasses("Bio::SearchIO"); exit } },
				  DEFAULT  => 'blast',
				  ARGCOUNT => ARGCOUNT_ONE,
				  ALIAS    => 'f|if|input_format',
				  SUMMARY  => "Input file format (anything supported by Bio::SearchIO)",
			      },

			      'force_basename' => {
				  DEFAULT  => [],
				  ARGCOUNT => ARGCOUNT_LIST,
				  ALIAS    => 'b',
				  SUMMARY  => "Derive query name from filename by  removing suffixes",
			      },

			      'input_args' => {
				  DEFAULT  => {},
				  ARGCOUNT => ARGCOUNT_HASH,
				  ALIAS    => 'ia',
				  SUMMARY  => "Options to be passed to the input parser.",
			      },

			      'type' => {
				  DEFAULT  => 'blastp',
				  ARGCOUNT => ARGCOUNT_ONE,
				  ALIAS    => 'a',
				  SUMMARY  => "Set the type of BLAST search (either BLAST or PSIBLAST supported)",
			      },

			      # Processing controls
			      'iteration'  => {
				  DEFAULT  => 0,
				  ARGCOUNT => ARGCOUNT_ONE,
				  ALIAS    => 'i',
				  SUMMARY  => "Set the maximum number of iterations to process. Results from additional rounds of PSI-BLAST will be ignored. If set a value < 1, all iterations are processed.",
			      },

			      'mode' => {
				  DEFAULT  => 'domain',
				  ARGCOUNT => ARGCOUNT_ONE,
				  ALIAS    => 'm',
				  SUMMARY  => "Shortcut to select a pre-defined set of subroutines to extract and manipulate column data from the Bio::Search objects. This is equivalemnt to set the same name to processors at all four levels of the Bio::Search object model (result, iteration, hit and HSP). See the L<--processor> option for details. 

The default processing mode generates the columns listed as the default columns (See option --column). You can also define your own processors and the set of columns you want to extract (See section L<Bio::Search model and processors>).",
			      },

			      'overlap' => {
				  DEFAULT  => 0.4,
				  ARGCOUNT => ARGCOUNT_ONE,
				  ALIAS    => 'o',
				  SUMMARY  => "Maximum acceptable overlap among different HSPs. If exceeded, ignore HSPs with higher e-values",
			      },

			      'pcut' => {
				  DEFAULT  => 10,
				  ARGCOUNT => ARGCOUNT_ONE,
				  ALIAS    => 'evalue|e',
				  SUMMARY  => "Maximum HSP e-value to include in output",
			      },

			      'threshold'  => {
				  DEFAULT  => 0.01,
				  ARGCOUNT => ARGCOUNT_ONE,
				  ALIAS    => 't',
				  SUMMARY  => "Inclusion threshold used by blastpgp",
			      },

			      'warn_on_error' => {
				  DEFAULT  => 0,
				  ARGCOUNT => ARGCOUNT_NONE,
				  SUMMARY => "Do not abort when parsing fails",
			      },

			      # Output
			      # Extract GIs from ids
			      'clean' => {
				  DEFAULT  => [],
				  ARGCOUNT => ARGCOUNT_LIST,
				  ALIAS => 'c',
				  SUMMARY => "Choose a method to parse the query and hit identifiers. May be either the name of a pre-defined subroutine or Perl code defining an anonymous subroutine. User-provided subroutine will be given three arguments: (1) the ID that must be processed, (2) a string specifying what argument is being processed (either 'query' or 'hit') and (3) a reference to the internal data structure (a BioPerl object) being processed. The subroutine must return the processed identifier as a string. Currently, the following subroutines are available as pre-defined methods for processing identifiers:

 cdd         : process CDD identifiers found by RPS-BLAST
               (extracts the domain name from the hit description) 
 genbank2gi  : if name matches regexp 'gi|\\d+|\\w+|+[^\\|]+', 
               returns the number after the first '|'
 genbank2acc : if name matches regexp 'gi|\\d+|\\w+|+[^\\|]+', 
               returns the string after the third '|'
 profiledb   : removes regexp (\\_\\S+)?\\.\\d+ from hit IDs
 none or 0   : disable identifier parsing
",
			      },

			      'column' => {
				  DEFAULT  => [ qw(hit_name query_name hit_start hit_end evalue query_coverage query_start query_end iteration bits hit_length) ],
				  ARGCOUNT => ARGCOUNT_LIST,
				  ALIAS => 'k',
				  SUMMARY => "Enter a user defined list of columns to add to the output. Use the --mode option to enable pre-defined column sets",
			      },

			      'header' => {
				  DEFAULT  => 0,
				  ARGCOUNT => ARGCOUNT_NONE,
				  ALIAS    => 'y',
				  SUMMARY  => "Add columns names to output table.",
			      },

			      'non_redundant_hsps' => {
				  DEFAULT  => 1,
				  ARGCOUNT => ARGCOUNT_NONE,
				  ALIAS    => 'nr',
				  SUMMARY  => "Whether to remove redundant (i.e. overlapping) HSPs, keeping only the best scoring (minimum e-value) ones",
			      },

			      'rename_query' => {
				  DEFAULT  => undef,
				  ARGCOUNT => ARGCOUNT_ONE,
				  ALIAS    => 'r',
				  SUMMARY  => "Change query identifier: either a string or perl code defining a closure (anonymoys subroutine reference). The subroutine receives as input the query name and the input file name and should return the new query name as a string.",
			      },

			      'single_query' => {
				  ALIAS    => 'sq',
				  DEFAULT  => 0,
				  ARGCOUNT => ARGCOUNT_NONE,
				  SUMMARY  => "If the input format is set to 'blast' (BLAST's default pairwise alignment), BioPerl's parser treats every iteration as a different BLAST report. Thus, when analysing data for a single query sequence, if the user chooses to select PSI-BLAST iterations (--iteration), this option will limit parsing to the first BLAST report corresponding to that iteration, thus avoiding processing of unselected iterations. Incidentally, this option will only parse the first query of multi-query report(s).",
			      },

			      'swap' => {
				  ALIAS    => 's',
				  DEFAULT  => 0,
				  ARGCOUNT => ARGCOUNT_NONE,
				  SUMMARY  => "Swap query and hit output columns",
			      },
	);

    # Compile rename_query subroutine
    if (defined $appconfig->rename_query) {
	my $ref = $appconfig->rename_query;
	$ref = eval $ref if ($ref =~ /\bsub\b.+\{.+\}/);
	die "Error compiling rename_query (option -r) subroutine: $@" if ($@);
	$appconfig->rename_query($ref);
    }

    # blastall/blastpgp -m 8 compatibility mode
    if ($appconfig->mode eq 'm8') {
	@{ $appconfig->clean } = ();
	$appconfig->non_redundant_hsps(0);
	@{ $appconfig->column } = qw(query_name hit_name percent_identity length_aln_total mismatch_total gaps_total query_start query_end hit_start hit_end evalue bits);
    } elsif ($appconfig->mode eq 'orthomcl') {
	@{ $appconfig->clean } = ();
	$appconfig->non_redundant_hsps(0);
	@{ $appconfig->column } = qw(query_name hit_name query_taxon hit_taxon evalue_matisse evalue_exponent percent_identity percent_match);
    }

    # Cleaning
    @{ $appconfig->clean } = () if (grep { /^(none|0)$/i } @{ $appconfig->clean });
    for (my $i=0; $i<=$#{ $appconfig->clean }; $i++) {
	my $ref = $appconfig->clean->[$i];
	if ($ref eq 'genbank2gi') {
	    $ref = \&genbank2gi;
	} elsif ($ref eq 'genbank2acc') {
	    $ref = \&genbank2acc;
	} elsif ($ref eq 'profiledb') {
	    $ref = \&profiledb;
	} elsif ($ref eq 'cdd') {
	    $ref = \&CDD;
	} elsif ($ref =~ /sub\s*\{.+\}\s*/i) {
	    $ref = eval "$ref";
	    die "Failed to compile method to clean sequence identifiers:\n$@" if ($@);
	} else {
	    die "Unknown clean subroutine $ref";
	}
	$appconfig->clean->[$i] = $ref;
    }

    # Check arguments
    if (! -t STDIN ) {
	my $dash = 0;
	for (my $i=0; $i<=$#ARGV; $i++) {
	    if ($ARGV[$i] eq "-") {
		$ARGV[$i] = \*STDIN;
		$dash = 1;
	    }
	}
	unshift(@ARGV,\*STDIN) unless ($dash);
    }

    return $appconfig;
}

# POD: start
# Documentation (use option -doc or --doc to see it!)
#
# AppConfig::AutoDoc can automatically extract Plain Old Documentation
# from within the caller program's, add descriptions of the options
# created by L<define> and do some pretty formatting for output.
# 
# Note that POD may be added anywhere in your program, thus allowing 
# the documentation for a program to be left side by side with the
# function's definition.

=head1 NAME

 blast2table - convert BLAST report in text table

=head1 SYNOPSIS

 # Parse a standard BLAST report named result.srch
 blast2table result.srch

 # Change the name of the query sequence
 blast2table -r MyQuery result.srch

 # Derive the query name from the filename by removing a suffix
 blast2table -b .srch DOM1.srch

 # Converting BLAST XML output in a table identical to the one produced
 # by BLAST using -m 8 
 blast2table -c none --nonr --type BLAST -f blastxml -k m8 file.xml > file.m8

=head1 DESCRIPTION

This program takes any Bio::SearchIO supported file and converts it to
a TAB separated text table. By default ("domain" mode) the following 
columns are included:

      Column     :         Description
                 :
 Hit             : hit identifier
 Query           : query identifier
 Hit start       : start of aligned region in the hit sequence
 Hit end         : end of aligned region in the hit sequence
 E-value         : alignment significance (expected value)
 Query coverage  : (query_end-query_start+1)/query_length*100
 Query start     : start of aligned region in the query sequence
 Query end       : end of aligned region in the query sequence
 Iteration       : PSI-BLAST iteration number

=head2 Bio::Search model

This program is based on the modules Bio::Search and Bio::SearchIO
of BioPerl and, therefore, it inherits the four layers of objects
defined by these libraries for the results of searches performed
with any given query:

 result     : mostly storing data on the query and search statistics
  iteration : represents the results of each round in iterated searches
    hit     : data on each sequence match found by the search
     HSP    : a set of alignments between regions of the hit and query

=head3 Processors

For each level of the Bio::Search hierarchy above subroutines may be
called to store the values of the output columns in an anonymous hash
using as key the output column names.

=head3 Modes

blast2table includes a set of pre-defined processors which can be selected
using the shortcut option --mode. The following modes are available:

=over

=item * domain   : generates a table listing non-overlapping sets of coordinates
in each hit that correspond to the queries

=item * m8       : dumps the search object in a format identical to the table 
produced by NCBI's BLAST programs using option -m 8

=item * orthomcl : creates tables with the same set of columns as generated
by the program orthomclBlastParser. This table can be loaded into OrthoMCL's 
SimilarSequences SQL table using orthomclLoadBlast.

=back

=cut

=head2 Supported input formats (--format option)

Use --format help to get a list of the parsers in your system.

Parsing is performed using BioPerl. Note that some parsers could fail due to
missing information required by blast2table. 

=head2 Other notes

To correctly identify when sequences were added to the PSSM 
and thus print only the E-value correponding to the first significant
alignment between query and hit, the user must set the inclusion 
threshold (-t) parameter to the value used when running BLAST.

The parameter to tolerate overlaps (--overlap) supports both
integers and float or scientific notation values. For integers, it
evaluates the amount of overlap in terms of the number of residues,
that should be smaller or equal to the value provided by the user.
For floats or scientific notation, the value is considered to be
the maximum fraction (percentage) of the hit region that was included
in the alignment. This is the default behaviour, since the default
value of this parameter is 0.4 (40%).

=head1 AUTHOR

 Robson Francisco de Souza

=cut
# POD: end


