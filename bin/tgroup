#!/usr/bin/env perl

use FindBin;
use lib "$FindBin::RealBin/../perl/lib";
use Statistics::Descriptive;
use strict;
use warnings;

# Parse command line options
my $CONFIG = parse_configuration();

# Parsing tables
my ($HEADER, %TABLE) = parse_input_files($CONFIG, @ARGV);

# Aggregate columns
my @output = ();
foreach my $key (keys %TABLE) {
    my $row = $TABLE{$key};
    my @row = ();
    foreach my $col (@{$CONFIG->include}) {
	#print STDERR join("\t",$key,$col,defined($row->[$col]) ? join(":",@{$row->[$col]}) : "undef"),"\n"; next;
	my @values = defined($row->[$col]) ? @{$row->[$col]} : $CONFIG->empty;
	if (exists $CONFIG->group_hash->{$col}) {
	    @values = aggregate("concat:distinct", @values);
	} else {
	    my $aggregator = exists $CONFIG->aggregator->{$col} ? $CONFIG->aggregator->{$col} : $CONFIG->default_aggregator;
	    @values = aggregate($aggregator, @{$row->[$col]});
	}
	push(@row, concat($CONFIG->cat_string, @values));
    }
    push(@output, [ @row ]);
}

# Align output
my @LENGTH = ();
if ($CONFIG->pad) {
    foreach my $row (@output) {
	for (my $i=0; $i<=$#{$row}; $i++) {
	    $LENGTH[$i] = length($row->[$i]) if (!defined $LENGTH[$i] || $LENGTH[$i] < length($row->[$i]));
	}
    }
}

# Sort and print
my $colIndex = 0;
print join($CONFIG->output_delimiter, map { pad($CONFIG,$LENGTH[$_],$HEADER->[$_] || "c".$colIndex++) } @{$CONFIG->include}),"\n" if ($CONFIG->parse_header);
foreach my $row (sort sort_matrix_rows @output) {
    print join($CONFIG->output_delimiter,map { pad($CONFIG, $LENGTH[$_], $row->[$_]) } 0..$#{$row}),"\n";
}

exit 0;

###############
# Subroutines
#

sub pad {
    my ($conf, $length, $text) = @_;
    if ($conf->pad) {
	return sprintf("%-${length}s", defined $text && length $text ? $text : $conf->empty);
    } else {
	return defined $text && length $text ? $text : $conf->empty;
    }
}

sub aggregate {
    my $aggregator = shift;
    my @result     = @_;
    my ($method, $qualifier) = split(":",$aggregator);

    # Apply distinct
    if (defined $qualifier && $qualifier eq 'distinct') {
	my %values = ();
	@result = grep { exists $values{$_} ? 0 : ++$values{$_} } @result;
    }

    # Select and apply aggregator
    if ($method eq 'count') {
	return scalar(@result);
    } elsif ($method eq 'concat') {
	return grep { defined && length } @result;
    } elsif ($method eq 'cat_count') {
	my %count = ();
	map { $count{$_}++ } @result;
	@result = map { "${_} [$count{$_}]" } sort keys %count;
	return @result;
    } elsif ($method eq 'first') {
	@result = ($result[0]);
    } elsif ($method eq 'last') {
	@result = ($result[$#result]);
    } else {
	my $stat = Statistics::Descriptive::Full->new();
	$stat->add_data(@result);
	if ($method eq 'range') {
	    @result = ($stat->min,$stat->max);
	} else {
	    @result = eval { return $stat->$method };
	}
	die "Error while trying to call Statistics:Descriptive method $method:\n$@" if ($@);
    }

    return @result;
}

# Remove column redundancy and concatenate observed values
sub concat {
    my $sep = shift;
    #my %list = (); map { $list{$_}++ } @_;
    #return join($sep, sort _compare keys %list);
    #return join($sep, sort _compare @_);
    return join($sep, @_);
}

#
sub parse_input_files {
    my $conf  = shift;
    my @files = @_;
    my $SEP  = $conf->input_delimiter;

    # Compile row filters
    my @F = (); # array of column values for each row
    my %H = (); # hash accessible to filter's code (starts empty)
    my @filter = ();
    if (scalar @{$CONFIG->filter}) {
	foreach my $rule (@{$CONFIG->filter}) {
	    my $ref = $rule;
	    if (-f "$rule") {
		open(RULE,"<$rule") || die "Could not load rules from file $rule";
		$ref = join(" ",map { chomp; $_ } grep { !/^\#/ } <RULE>);
		close(RULE);
	    }
	    $ref = eval "sub { $ref }";
	    die "Error while compiling output filter $rule\n$@" if ($@);
	    push(@filter, $ref);
	}
    }

    # Parse table(s)
    my $header = [];
    my %table = ();
    my $ncol = 0;
    foreach my $file (@files) {
	open(F,"<$file") || die "Could not open table $file";
	$H{"current_file"} = $file;
	my $parsed_header = 0;
      F1: while (<F>) {
	  chomp;
	  if ($conf->unpad) { # Unpad
	      @F = map { s/^\s*//; s/\s*$//; $_ } split(/$SEP/);
	  } else {
	      @F = split(/$SEP/);
	  }

	  # Parse header
	  if (!$parsed_header && $conf->parse_header) {
	      $header = [ @$header, @F[scalar(@$header)..$#F] ] if ($#{$header} < $#F);
	      my %count = ();
	      my %colIndex = ();
	      for (my $i=0; $i<=$#{$header}; $i++) {
		  $count{$header->[$i]}++;
		  $header->[$i] .= "_" . $count{$header->[$i]} if ($conf->rename_duplicates && $count{$header->[$i]} > 1);
		  push(@{$colIndex{$header->[$i]}}, $i);
	      }

	      # Group and exclude
	      foreach my $option (qw(exclude group)) {
		  my $ref = $conf->get($option);
		  if (scalar @{$ref}) {
		      my $hash = $conf->get($option . '_hash');
		      my %nextIdx = ();
		      for (my $i=0; $i<= $#{$ref}; $i++) {
			  my $column = $ref->[$i];
			  my $index = $column;
			  if (exists $colIndex{$column}) {
			      $index = (!exists $nextIdx{$column} || $nextIdx{$column} < $#{$colIndex{$column}}) ? $nextIdx{$column}++ : $#{$colIndex{$column}};
			      $index = $colIndex{$column}->[$index];
			  }
			  delete $hash->{$column};
			  $hash->{$index}++;
		      }
		  }
	      }

	      # Include
	      if (scalar @{$conf->include}) {
		  my $incRef = $conf->include;
		  my %nextIdx = ();
		  for (my $i=0; $i<= $#{$incRef}; $i++) {
		      my $column = $incRef->[$i];
		      my $index = $column;
		      if (exists $colIndex{$column}) {
			  $index = (!exists $nextIdx{$column} || $nextIdx{$column} < $#{$colIndex{$column}}) ? $nextIdx{$column}++ : $#{$colIndex{$column}};
			  $index = $colIndex{$column}->[$index];
		      }
		      $incRef->[$i] = $index;
		  }
	      }

	      #$conf->_dump_to_stderr && exit;
	      $parsed_header = 1;
	      next F1;
	  }

	  # Apply row filters
	  if (scalar @filter) {
	      for (my $i=0; $i<=$#filter; $i++) {
		  my $val = $filter[$i]->();
		  print STDERR "$_\nFilter $i returned '$val' when applied to the row above\n" if ($conf->debug);
		  next F1 if (!$val);
	      }
	  }

	  # Store number of columns
	  $ncol = $#F unless ($ncol > $#F);
	  #die "File $file does not preserve the number of columns" if (scalar(@F) != $ncol);

	  # Row key
	  my @key = map { (defined $F[$_] && length $F[$_]) ? $F[$_] : '_mising_key_' } keys %{$conf->group_hash};
	  my $key = join("\cA",@key);

	  # Parse row
	  $table{$key} = [] unless (exists $table{$key});
	  for (my $col=0; $col<=$#F; $col++) {
	      push(@{ $table{$key}->[$col] }, $F[$col]);
	  }
      } # F1: while (<$fh>)
	close(F);
    } # foreach my $file (@ARGV)

    # Set list of output columns
    if (defined $ncol && !scalar @{$conf->include}) {
	foreach my $column (0..$ncol) {
	    $conf->include($column) unless (exists $conf->exclude_hash->{$column});
	}
    }

    return ($header, %table);
}

sub sort_matrix_rows {
    my $ret = 0;
    foreach my $field (@{$CONFIG->sort}) {
	my $reverse = ($field =~ /[\, ]+r$/) ? 1 : 0;
	$field =~ s/[\, ]+r$//;
	my @A = ($a->[$field]);
	my @B = ($b->[$field]);
	if (exists($CONFIG->aggregator->{$field}) && $CONFIG->aggregator->{$field} =~ /^concat/) {
	    my $SEP = $CONFIG->cat_string;
	    $SEP = "\\$SEP" unless ($SEP =~ /\w/);
	    @A = split($SEP,$a->[$field]);
	    @B = split($SEP,$b->[$field]);
	}
	foreach my $A (@A) {
	    foreach my $B (@B) {
		if ($A =~ /^\d+\.?\d*e?\-?\d*$/ &&
		    $B =~ /^\d+\.?\d*e?\-?\d*$/) {
		    $ret ||= ($A <=> $B);
		} else {
		    $ret ||= ($A cmp $B);
		}
		$ret *= -1 if ($reverse);
	    }
	}
    }
    return $ret;
}

sub _compare {
    if ($a =~ /^\d+\.?\d*e?\-?\d*$/ &&
	$b =~ /^\d+\.?\d*e?\-?\d*$/) {
	return ($a <=> $b);
    } else {
	return ($a cmp $b);
    }
}

sub parse_configuration {
    # Parser definition
    use Application::Config qw(:argcount GetTableToolsConfig expand_numeric_interval);
    my $appconfig = GetTableToolsConfig(

	'aggregator' => {
	    ALIAS    => 'a',
	    ARGCOUNT => ARGCOUNT_HASH,
	    DEFAULT  => {},
	    SUMMARY  => "Select an aggregator to collapse a column. Unless specified using this option, all non-group columns will be collapsed using the default aggregator (option --default_aggregator). Note that no qualifier is applied prior to aggregation unless explicitly requested by the user, e.g. the default aggregator (see below) explicitly request the 'distinct' qualifier to take effect before concatenating values.",
			      },

	'cat_string' => {
	    ALIAS    => 'c',
	    ARGCOUNT => ARGCOUNT_ONE,
	    DEFAULT  => ':',
	    SUMMARY  => "String to separate concatenated colapsed values.",
	},

	'default_aggregator' => {
	    ALIAS    => 'd',
	    ARGCOUNT => ARGCOUNT_ONE,
	    DEFAULT  => 'concat:distinct',
	    SUMMARY  => "The default aggregator for all collapsed columns if no column-specific aggregator is set by the user (see --aggregator).",
	},

	'exclude' => {
	    ALIAS    => 'x',
	    ACTION   => \&expand_numeric_interval,
	    ARGCOUNT => ARGCOUNT_LIST,
	    DEFAULT  => [],
	    SUMMARY  => "List of columns to remove from the output table. Columns may be selected using interval syntax of the form start..end, e.g. 0..4 refers to the first to fifth elements.",
	},

	"filter" => {
	    ALIAS    => 'f',
	    ARGCOUNT => ARGCOUNT_LIST,
	    DEFAULT  => [],
	    SUMMARY  => "filter(s) to select rows in input table (Perl code)",
	},

	"group" => {
	    ALIAS    => 'g',
	    ARGCOUNT => ARGCOUNT_LIST,
	    DEFAULT  => [ 0 ],
	    SUMMARY  => "(list of) reference column(s)",
	},

	'include' => {
	    ALIAS    => 'i',
	    ACTION   => \&expand_numeric_interval,
	    ARGCOUNT => ARGCOUNT_LIST,
	    DEFAULT  => [],
	    SUMMARY  => "List of columns to include in output table. Columns may be selected using interval syntax of the form start..end, e.g. 0..4 refers to the first to fifth elements.",
	});

    # Indexing grouping columns (array -> hash)
    $appconfig->define("group_hash", {
	DEFAULT  => {},
	ARGCOUNT => ARGCOUNT_HASH,
    });
    map { $appconfig->group_hash->{$_}++ } @{$appconfig->group};

    # Test and index excluded columns (array -> hash)
    $appconfig->define("exclude_hash", {
	DEFAULT  => {},
	ARGCOUNT => ARGCOUNT_HASH,
    });
    foreach my $column (@{$appconfig->exclude}) {
	die "Can't remove column $column from output, because it is being used for grouping."
	    if (exists $appconfig->group_hash->{$column});
	$appconfig->exclude_hash->{$column}++ unless (grep { $_ eq $column } @{$appconfig->include});
    }

    # Add standard input if requested or if the list of arguments is empty
    push(@ARGV,"-") if (!scalar @ARGV);

    return $appconfig;
}

__END__

# POD: start
# Documentation (use option -doc or --doc to see it!)
#
# AppConfig::AutoDoc can (1) automatically extract Plain Old 
# Documentation from within the caller program's, (2) add 
# descriptions (SUMMARY) to the options created by L<define>
# and (3) print all this after some pretty formatting.
# 
# Note that POD may be added anywhere in your program, thus
# allowing the documentation for a program to be left side by
# side with function definitions.

=head1 NAME

 tgroup - collapse/group table rows

=head1 SYNOPSIS

Suppose you have a TAB-separated table t1.tsv containing the rows

 1 2 a
 1 4 b
 2 6 c

then a tgroup command like

tgroup t1.tsv

will concatenate the contents of the second and third columns
and generate a table like

 1 2:4 a:b
 2 6   c

Note: this is the same as the command tgroup -g 0 t1.tsv

A somewhat more complex example is to use column 3 to count
the number of rows that were merged, instead of concatenating
the column:

tgroup -a 2=count t1.tsv

will generate the table

 1 2:4 2
 2 6   1

Additional examples: group table from pipe by
first (0), second (1) and nineth (8) columns:

cat table.tsv | tgroup -g 0 -g 1 -g 8

Ignore rows from input table that have "unknown" in the first
column, group remaining rows by second column and remove the
fifth column and all columns from 9 to 15:

tgroup -f '$F[0] eq "unknown"' -g 1 -x 5 -x 9..15 table.tsv

=head1 DESCRIPTION

tgroup is a program that merges (collapses) rows in a tables by
aggregating, for each collapsed column, the values from rows that
have the same value in a (set of) reference columns.

Note: just like perl-arrays, tgroup identifies columns using a 
zero-based index. That means users must refer to a column by its
number minus one (index = column number - 1). Support for column
names is planned for future versions.

=head2 AGGREGATORS

Aggregators are subroutines that are applied to collapsed columns
in order to merge their contents into a single value. Two kinds
of aggregators are supported by tgroup:

=over

=item * Summary statistics supported by Statistics::Descriptive

=item * Subroutines defined in tgroup's code

=back

The agggregators defined by tgroup include:

=over

=item 1. concat => concatenate column strings

=item 2. range  => minimum and maximum for numeric columns

=back

See "perldoc Statistics::Descriptive" for information on the
methods provided by this library.

=head2 QUALIFIERS

Qualifiers add preprocessing steps and/or additional control to
aggregators, thus allowing extension of an aggregator's functionality.
Qualifiers are activated when specifying aggregators (options
--default_aggregator and --aggregator) by adding a qualifier name
to the aggregator's name after a colon (:). For example,
while the command

tgroup -a 1=count table.tsv

counts the number of ROWS for each repeated value in the first column
of table.tsv, the command

tgroup -a 1=count:distinct

will count the number of UNIQUE values found in the second column 
regardless of how many times a given value appears in that column.
Currently, the following aggregators are available:

=over

=item * 'distinct' => remove column redundancy prior to aggregation
(same as DISTINCT in SQL's SELECT)

=back

=head1 AUTHOR

 Robson Francisco de Souza

=cut
# POD: end
