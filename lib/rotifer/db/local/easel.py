__doc__ = """
Rotifer's connections to local databases
========================================
"""

import re
import os
import types
import typing
import subprocess
import numpy as np
import pandas as pd
from Bio import SeqIO
from io import StringIO

import rotifer
import rotifer.db.parallel
from rotifer.core.functions import loadConfig
logger = rotifer.logging.getLogger(__name__)

# Defaults
_defaults = {
    'local_database_path': [ os.path.join(rotifer.config['data'],"fadb","nr","nr") ],
    "batch_size": 200,
    "threads": int(np.floor(os.cpu_count()/2)),
}
config = loadConfig(__name__.replace('rotifer.',':'), defaults = _defaults)

class FastaCursor(rotifer.db.parallel.SimpleParallelProcessCursor):
    """
    Fetch biomolecular sequences using Easel's esl-sfetch.

    Parameters
    ----------
    database_path: string
      Path to a FASTA file.
    batch_size: int, default 1
      Number of accessions per batch
    threads: integer, default 3
      Number of simultaneous threads to run
    progress: boolean, deafult False
      Whether to print a progress bar

    """
    def __init__(
            self,
            database_path=config["local_database_path"],
            progress=True,
            tries=1,
            batch_size = config['batch_size'],
            threads = config['threads'] or _defaults['threads'],
            *args, **kwargs):
        threads = threads or _defaults['threads']
        super().__init__(progress=progress, tries=1, batch_size=batch_size, threads=threads, *args, **kwargs)
        self.executable = "esl-sfetch"
        self.maxgetitem = 1
        if isinstance(database_path,str) or not isinstance(database_path,typing.Iterable):
            database_path = [ database_path ]
        self.path = []
        for p in database_path:
            if not os.path.exists(p):
                logger.error(f'{p}: no such file!')
                continue
            if not os.path.exists(p + ".ssi"):
                logger.warn(f'Building {self.executable} index for {p}...')
                try:
                    subprocess.run([self.executable,"--index",p])
                except:
                    logger.error("Unable to create index for file {p} ({self.executable})")
                    continue
            self.path.append(p)
        if len(self.path) == 0:
            logger.critical("No index or database for executable {self.executable} in {self.path}")

    def _clean_description(self, seqrec):
        seqrec.description = re.sub("\x01.+", "", seqrec.description.replace(seqrec.id, "").lstrip())
        return seqrec

    def getids(self, obj):
        """
        Extract accessions from the objects generated by parser().

        Returns
        -------
        A set of strings.
        """
        import typing
        if isinstance(obj,list) or isinstance(obj,tuple):
            return set([ x.id for x in obj ])
        else:
            return {obj.id}

    def fetcher(self, accession, *args, **kwargs):
        """
        Fetch one sequence from the database.

        Returns
        -------
        A Bio.SeqRecord object
        """
        import tempfile
        from subprocess import Popen, PIPE
        targets = self.parse_ids(accession)
        data = ""
        for db in self.path:
            missing = set()
            while len(targets) > 0:
                if len(targets) == 1:
                    p = Popen([self.executable,db,next(iter(targets))], stderr=PIPE, stdout=PIPE, text=True)
                    o, e = p.communicate()
                else:
                    f = tempfile.NamedTemporaryFile(mode="w+t", delete=True)
                    print("\n".join(list(targets)), file=f)
                    f.flush()
                    p = Popen([self.executable,"-f",db,f.name], stderr=PIPE, stdout=PIPE, text=True)
                    o, e = p.communicate()
                if len(e) > 0:
                    missing.update({e.split(" ")[1]})
                found = set()
                if len(o) > 0:
                    data += o
                    found = set([ x.replace(">","").split(" ")[0] for x in o.split("\n") if len(x) > 0 and x[0] == ">" ])
                    missing.discard(found)
                targets = targets - found - missing
            targets = missing
            if not targets:
                break
        if targets:
            self.update_missing(targets, "Not found")
        return StringIO(data)

    def parser(self, stream, accession, *args, **kwargs):
        sequence = []
        for seq in SeqIO.parse(stream,"fasta"):
            seq = self._clean_description(seq)
            sequence.append(seq)
        stream.close()
        return sequence
