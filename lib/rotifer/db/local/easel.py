__doc__ = """
Rotifer's connections to local databases
========================================
"""

import re
import os
import types
import typing
import subprocess
import numpy as np
import pandas as pd
from Bio import SeqIO
from io import StringIO

import rotifer
import rotifer.db.parallel
from rotifer import GlobalConfig
from rotifer.core.functions import loadConfig
import rotifer.devel.beta.sequence as rdbs
logger = rotifer.logging.getLogger(__name__)

# Defaults
config = loadConfig(__name__.replace('rotifer.',':'), defaults = {
    'local_database_path': [ os.path.join(GlobalConfig['data'],"fadb","nr","nr") ],
})

class FastaCursor(rotifer.db.parallel.SimpleParallelProcessCursor):
    """
    Fetch biomolecular sequences using Easel's esl-sfetch.

    Parameters
    ----------
    database_path: string
      Path to a FASTA file.
    batch_size: int, default 1
      Number of accessions per batch
    threads: integer, default 3
      Number of simultaneous threads to run
    progress: boolean, deafult False
      Whether to print a progress bar

    """
    def __init__(
            self,
            database_path=config["local_database_path"],
            progress=True,
            tries=1,
            batch_size=200,
            threads=int(np.floor(os.cpu_count()/2)),
            *args, **kwargs):
        super().__init__(progress=progress, tries=1, batch_size=batch_size, threads=threads, *args, **kwargs)
        self.executable = "esl-sfetch"
        self.maxgetitem = 1
        if isinstance(database_path,str) or not isinstance(database_path,typing.Iterable):
            database_path = [ database_path ]
        self.path = []
        for p in database_path:
            if not os.path.exists(p):
                logger.error(f'{p}: no such file!')
                continue
            if not os.path.exists(p + ".ssi"):
                logger.warn(f'Building {self.executable} index for {p}...')
                try:
                    subprocess.run([self.executable,"--index",p])
                except:
                    logger.error("Unable to create index for file {p} ({self.executable})")
                    continue
            self.path.append(p)
        if len(self.path) == 0:
            logger.critical("No index or database for executable {self.executable} in {self.path}")

    def _clean_description(self, seqrec):
        seqrec.description = re.sub("\x01.+", "", seqrec.description.replace(seqrec.id, "").lstrip())
        return seqrec

    def getids(self, obj):
        """
        Extract accessions from the objects generated by parser().

        Returns
        -------
        A set of strings.
        """
        import typing
        if isinstance(obj,list) or isinstance(obj,tuple):
            return set([ x.id for x in obj ])
        else:
            return {obj.id}

    def __getitem__(self, accession):
        targets = self.parse_ids(accession)
        objlist = []
        todo = targets.copy()
        for db in self.path:
            #logger.debug(f'Process {os.getpid()}, Database: {db}, Accessions: {len(targets)}') 
            result = super().__getitem__(todo, db)
            if result == None:
                continue
            if isinstance(result,list):
                objlist.extend(result)
            else:
                objlist.append(result)
            todo = todo.intersection(self._missing.keys())
            if not todo:
                break
        if len(targets) == 1 and len(objlist) == 1:
            objlist = objlist[0]
        return objlist

    def fetcher(self, accession, *args, **kwargs):
        """
        Fetch one sequence from the database.

        Returns
        -------
        A Bio.SeqRecord object
        """
        import tempfile
        from subprocess import Popen, PIPE
        targets = self.parse_ids(accession)
        data = ""
        missing = set()
        for db in self.path:
            while len(targets) > 0:
                with tempfile.NamedTemporaryFile(mode="w+t", delete=True) as f:
                    print("\n".join(list(targets)), file=f)
                    f.flush()
                    p = Popen(["esl-sfetch","-f",db,f.name], stderr=PIPE, stdout=PIPE, text=True)
                    o, e = p.communicate()
                    if len(e) > 0:
                        missing.update({e.split(" ")[1]})
                    done = set()
                    if len(o) > 0:
                        data += o
                        done = set([ x.replace(">","").split(" ")[0] for x in o.split("\n") if len(x) > 0 and x[0] == ">" ])
                        missing.discard(done)
                    targets = targets - missing - done
            targets = missing
            if not targets:
                break
        if missing:
            self.update_missing(missing, "Not found")
        return StringIO(data)

    def parser(self, stream, accession, *args, **kwargs):
        sequence = []
        for seq in SeqIO.parse(stream,"fasta"):
            seq = self._clean_description(seq)
            sequence.append(seq)
        stream.close()
        return sequence

